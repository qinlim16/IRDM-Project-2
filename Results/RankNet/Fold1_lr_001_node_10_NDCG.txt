
Discard orig. features
Training data:	MSLR-WEB10K/Fold1/restructure_train.txt
Test data:	MSLR-WEB10K/Fold1/restructure_test.txt
Validation data:	MSLR-WEB10K/Fold1/restructure_vali.txt
Feature vector representation: Dense.
Ranking method:	RankNet
Feature description file:	Unspecified. All features will be used.
Train metric:	NDCG@10
Test metric:	NDCG@10
Feature normalization: No

[+] RankNet's Parameters:
No. of epochs: 100
No. of hidden layers: 1
No. of hidden nodes per layer: 10
Learning rate: 0.01

Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]... [Done.]            
(5946 ranked lists, 72342 entries read)
Reading feature file [MSLR-WEB10K/Fold1/restructure_vali.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_vali.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_vali.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_vali.txt]... [Done.]            
(1983 ranked lists, 23526 entries read)
Reading feature file [MSLR-WEB10K/Fold1/restructure_test.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_test.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_test.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_test.txt]... [Done.]            
(1980 ranked lists, 24153 entries read)
Initializing... [Done]
-----------------------------------------
Training starts...
--------------------------------------------------
#epoch  | % mis-ordered  | NDCG@10-T | NDCG@10-V | 
        |   pairs        |           |           | 
--------------------------------------------------
1       | 0.1123         | 0.5081    | 0.5107    | 
2       | 0.1189         | 0.4996    | 0.5056    | 
3       | 0.0733         | 0.497     | 0.5024    | 
4       | 0.1057         | 0.4991    | 0.5028    | 
5       | 0.095          | 0.4944    | 0.4999    | 
6       | 0.0462         | 0.4962    | 0.5032    | 
7       | 0.0462         | 0.4961    | 0.5035    | 
8       | 0.0408         | 0.4971    | 0.5021    | 
9       | 0.1472         | 0.5002    | 0.5007    | 
10      | 0.1215         | 0.4954    | 0.5036    | 
11      | 0.0318         | 0.4964    | 0.5017    | 
12      | 0.0502         | 0.4956    | 0.5013    | 
13      | 0.1163         | 0.4968    | 0.503     | 
14      | 0.0575         | 0.4962    | 0.5008    | 
15      | 0.1107         | 0.4979    | 0.5007    | 
16      | 0.0498         | 0.4984    | 0.5031    | 
17      | 0.0711         | 0.4964    | 0.5024    | 
18      | 0.0877         | 0.5019    | 0.5048    | 
19      | 0.0472         | 0.4969    | 0.5047    | 
20      | 0.0492         | 0.499     | 0.5048    | 
21      | 0.0519         | 0.4968    | 0.5036    | 
22      | 0.1279         | 0.5006    | 0.5063    | 
23      | 0.0567         | 0.4965    | 0.5036    | 
24      | 0.066          | 0.4967    | 0.5028    | 
25      | 0.0502         | 0.4961    | 0.5021    | 
26      | 0.0407         | 0.4962    | 0.5019    | 
27      | 0.0426         | 0.4958    | 0.5013    | 
28      | 0.039          | 0.4957    | 0.502     | 
29      | 0.0454         | 0.4964    | 0.5018    | 
30      | 0.0372         | 0.496     | 0.5028    | 
31      | 0.0367         | 0.4957    | 0.5016    | 
32      | 0.0446         | 0.4965    | 0.503     | 
33      | 0.0411         | 0.4968    | 0.503     | 
34      | 0.045          | 0.4961    | 0.5023    | 
35      | 0.0467         | 0.4962    | 0.5024    | 
36      | 0.0413         | 0.4958    | 0.5027    | 
37      | 0.049          | 0.496     | 0.5025    | 
38      | 0.0406         | 0.4955    | 0.5018    | 
39      | 0.0445         | 0.4959    | 0.5024    | 
40      | 0.0445         | 0.4958    | 0.5023    | 
41      | 0.047          | 0.496     | 0.5031    | 
42      | 0.0461         | 0.4958    | 0.5029    | 
43      | 0.0467         | 0.496     | 0.5024    | 
44      | 0.0392         | 0.4954    | 0.5022    | 
45      | 0.0452         | 0.496     | 0.5029    | 
46      | 0.0372         | 0.4967    | 0.5032    | 
47      | 0.0454         | 0.4955    | 0.5034    | 
48      | 0.0383         | 0.4954    | 0.502     | 
49      | 0.0434         | 0.4961    | 0.5032    | 
50      | 0.0434         | 0.4974    | 0.5031    | 
51      | 0.0387         | 0.4954    | 0.5024    | 
52      | 0.0446         | 0.4961    | 0.5029    | 
53      | 0.0519         | 0.496     | 0.5027    | 
54      | 0.0477         | 0.4997    | 0.5063    | 
55      | 0.04           | 0.4955    | 0.5022    | 
56      | 0.0384         | 0.4958    | 0.5023    | 
57      | 0.0313         | 0.4965    | 0.504     | 
58      | 0.0341         | 0.4962    | 0.5025    | 
59      | 0.0327         | 0.4962    | 0.5027    | 
60      | 0.0302         | 0.4959    | 0.5028    | 
61      | 0.0321         | 0.4961    | 0.5034    | 
62      | 0.0334         | 0.4963    | 0.503     | 
63      | 0.0343         | 0.4964    | 0.5033    | 
64      | 0.0342         | 0.4949    | 0.5023    | 
65      | 0.0313         | 0.4958    | 0.5029    | 
66      | 0.0384         | 0.4965    | 0.5032    | 
67      | 0.0368         | 0.496     | 0.5026    | 
68      | 0.0361         | 0.4957    | 0.5032    | 
69      | 0.0389         | 0.4956    | 0.503     | 
70      | 0.0325         | 0.496     | 0.5028    | 
71      | 0.0404         | 0.4965    | 0.502     | 
72      | 0.0342         | 0.4966    | 0.5029    | 
73      | 0.0365         | 0.4951    | 0.5027    | 
74      | 0.0353         | 0.4959    | 0.5032    | 
75      | 0.0358         | 0.4964    | 0.5031    | 
76      | 0.0398         | 0.4958    | 0.5036    | 
77      | 0.0628         | 0.4944    | 0.5004    | 
78      | 0.0428         | 0.4967    | 0.5014    | 
79      | 0.044          | 0.4961    | 0.5038    | 
80      | 0.0381         | 0.4955    | 0.5033    | 
81      | 0.039          | 0.4972    | 0.5025    | 
82      | 0.0349         | 0.4963    | 0.5035    | 
83      | 0.0309         | 0.4953    | 0.5033    | 
84      | 0.0325         | 0.496     | 0.5025    | 
85      | 0.0302         | 0.4959    | 0.5028    | 
86      | 0.0342         | 0.4968    | 0.502     | 
87      | 0.031          | 0.4964    | 0.501     | 
88      | 0.0328         | 0.4976    | 0.502     | 
89      | 0.0324         | 0.4969    | 0.5035    | 
90      | 0.0346         | 0.4964    | 0.5048    | 
91      | 0.1148         | 0.495     | 0.5033    | 
92      | 0.0364         | 0.4954    | 0.5014    | 
93      | 0.0352         | 0.4953    | 0.5003    | 
94      | 0.0555         | 0.4967    | 0.5031    | 
95      | 0.0311         | 0.4959    | 0.5032    | 
96      | 0.0296         | 0.4967    | 0.5029    | 
97      | 0.0494         | 0.4965    | 0.504     | 
98      | 0.0315         | 0.4957    | 0.5024    | 
99      | 0.059          | 0.4967    | 0.5034    | 
100     | 0.0549         | 0.4981    | 0.5033    | 
--------------------------------------------------
Finished sucessfully.
NDCG@10 on training data: 0.5081
NDCG@10 on validation data: 0.5107
---------------------------------
NDCG@10 on test data: 0.4988
