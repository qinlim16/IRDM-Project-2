
Discard orig. features
Training data:	MSLR-WEB10K/Fold5/restructure_train.txt
Test data:	MSLR-WEB10K/Fold5/restructure_test.txt
Validation data:	MSLR-WEB10K/Fold5/restructure_vali.txt
Feature vector representation: Dense.
Ranking method:	RankNet
Feature description file:	Unspecified. All features will be used.
Train metric:	ERR@10
Test metric:	ERR@10
Highest relevance label (to compute ERR): 4
Feature normalization: No

[+] RankNet's Parameters:
No. of epochs: 100
No. of hidden layers: 1
No. of hidden nodes per layer: 10
Learning rate: 0.03

Reading feature file [MSLR-WEB10K/Fold5/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold5/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold5/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold5/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold5/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold5/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold5/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold5/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold5/restructure_train.txt]... [Done.]            
(5941 ranked lists, 72261 entries read)
Reading feature file [MSLR-WEB10K/Fold5/restructure_vali.txt]: 0... Reading feature file [MSLR-WEB10K/Fold5/restructure_vali.txt]: 0... Reading feature file [MSLR-WEB10K/Fold5/restructure_vali.txt]: 0... Reading feature file [MSLR-WEB10K/Fold5/restructure_vali.txt]... [Done.]            
(1984 ranked lists, 24234 entries read)
Reading feature file [MSLR-WEB10K/Fold5/restructure_test.txt]: 0... Reading feature file [MSLR-WEB10K/Fold5/restructure_test.txt]: 0... Reading feature file [MSLR-WEB10K/Fold5/restructure_test.txt]: 0... Reading feature file [MSLR-WEB10K/Fold5/restructure_test.txt]... [Done.]            
(1983 ranked lists, 23526 entries read)
Initializing... [Done]
-----------------------------------------
Training starts...
--------------------------------------------------
#epoch  | % mis-ordered  | ERR@10-T  | ERR@10-V  | 
        |   pairs        |           |           | 
--------------------------------------------------
1       | 0.0859         | 0.1366    | 0.1362    | 
2       | 0.1215         | 0.1334    | 0.1389    | 
3       | 0.0431         | 0.1351    | 0.1388    | 
4       | 0.1295         | 0.1322    | 0.1345    | 
5       | 0.1634         | 0.1322    | 0.1359    | 
6       | 0.0507         | 0.1347    | 0.1365    | 
7       | 0.1462         | 0.1384    | 0.1445    | 
8       | 0.104          | 0.1326    | 0.1362    | 
9       | 0.1633         | 0.1319    | 0.1344    | 
10      | 0.1318         | 0.1391    | 0.1426    | 
11      | 0.1676         | 0.1333    | 0.1374    | 
12      | 0.0928         | 0.1343    | 0.1405    | 
13      | 0.0644         | 0.1349    | 0.1402    | 
14      | 0.1715         | 0.1302    | 0.1337    | 
15      | 0.143          | 0.1368    | 0.1388    | 
16      | 0.153          | 0.1391    | 0.1428    | 
17      | 0.0991         | 0.1316    | 0.1347    | 
18      | 0.0757         | 0.1388    | 0.1442    | 
19      | 0.1199         | 0.1395    | 0.1444    | 
20      | 0.1074         | 0.1274    | 0.1304    | 
21      | 0.0777         | 0.1278    | 0.1292    | 
22      | 0.1098         | 0.1367    | 0.1376    | 
23      | 0.1567         | 0.1382    | 0.1419    | 
24      | 0.0986         | 0.1375    | 0.1411    | 
25      | 0.0805         | 0.1411    | 0.1437    | 
26      | 0.0466         | 0.1264    | 0.1299    | 
27      | 0.1248         | 0.1272    | 0.1299    | 
28      | 0.1758         | 0.14      | 0.1442    | 
29      | 0.1009         | 0.1325    | 0.1363    | 
30      | 0.1473         | 0.1345    | 0.1389    | 
31      | 0.1165         | 0.1336    | 0.1362    | 
32      | 0.0702         | 0.1266    | 0.129     | 
33      | 0.0356         | 0.1363    | 0.1384    | 
34      | 0.0293         | 0.1381    | 0.1396    | 
35      | 0.1591         | 0.1288    | 0.1314    | 
36      | 0.1119         | 0.1352    | 0.1376    | 
37      | 0.0198         | 0.1279    | 0.131     | 
38      | 0.0227         | 0.1297    | 0.1315    | 
39      | 0.0337         | 0.127     | 0.1307    | 
40      | 0.1443         | 0.1358    | 0.1371    | 
41      | 0.0283         | 0.1323    | 0.1338    | 
42      | 0.018          | 0.1275    | 0.1305    | 
43      | 0.0519         | 0.1327    | 0.1335    | 
44      | 0.0142         | 0.1293    | 0.1309    | 
45      | 0.0161         | 0.1343    | 0.1345    | 
46      | 0.0634         | 0.1276    | 0.1295    | 
47      | 0.082          | 0.1336    | 0.1363    | 
48      | 0.05           | 0.1389    | 0.1378    | 
49      | 0.0784         | 0.1321    | 0.1357    | 
50      | 0.0823         | 0.1269    | 0.1294    | 
51      | 0.0345         | 0.1275    | 0.1301    | 
52      | 0.0315         | 0.1294    | 0.1305    | 
53      | 0.003          | 0.1282    | 0.1312    | 
54      | 0.0316         | 0.13      | 0.1344    | 
55      | 0.0026         | 0.1298    | 0.1317    | 
56      | 0.084          | 0.127     | 0.1294    | 
57      | 0.0332         | 0.1275    | 0.1298    | 
58      | 0.0034         | 0.1279    | 0.1305    | 
59      | 0.0304         | 0.1276    | 0.1299    | 
60      | 0.0136         | 0.1308    | 0.1331    | 
61      | 0.0926         | 0.1336    | 0.138     | 
62      | 0.0024         | 0.1282    | 0.1302    | 
63      | 0.0039         | 0.1291    | 0.1309    | 
64      | 0.0031         | 0.1291    | 0.1312    | 
65      | 0.0974         | 0.1365    | 0.1412    | 
66      | 0.0132         | 0.1345    | 0.1343    | 
67      | 0.0109         | 0.1309    | 0.1329    | 
68      | 0.0801         | 0.133     | 0.1345    | 
69      | 0.0251         | 0.1271    | 0.1297    | 
70      | 0.003          | 0.1282    | 0.1305    | 
71      | 0.0253         | 0.1312    | 0.1339    | 
72      | 0.1401         | 0.1298    | 0.1317    | 
73      | 0.0118         | 0.1279    | 0.1308    | 
74      | 0.0294         | 0.128     | 0.1298    | 
75      | 0.0248         | 0.1333    | 0.1358    | 
76      | 0.0142         | 0.1313    | 0.1339    | 
77      | 0.1056         | 0.1359    | 0.1367    | 
78      | 0.0319         | 0.1329    | 0.1342    | 
79      | 0.0036         | 0.1282    | 0.1312    | 
80      | 0.0242         | 0.1279    | 0.1309    | 
81      | 0.108          | 0.1315    | 0.1338    | 
82      | 0.012          | 0.1308    | 0.1328    | 
83      | 0.0136         | 0.128     | 0.1305    | 
84      | 0.0097         | 0.1288    | 0.1309    | 
85      | 0.0205         | 0.1279    | 0.1306    | 
86      | 0.0045         | 0.1278    | 0.1307    | 
87      | 0.0198         | 0.1281    | 0.1301    | 
88      | 0.0372         | 0.1291    | 0.1302    | 
89      | 0.0179         | 0.1278    | 0.1294    | 
90      | 0.0425         | 0.1285    | 0.1309    | 
91      | 0.0467         | 0.1279    | 0.1303    | 
92      | 0.016          | 0.1278    | 0.1298    | 
93      | 0.0041         | 0.1281    | 0.1304    | 
94      | 0.0057         | 0.1282    | 0.1312    | 
95      | 0.0056         | 0.1287    | 0.131     | 
96      | 0.0344         | 0.1291    | 0.1308    | 
97      | 0.0144         | 0.1314    | 0.134     | 
98      | 0.0041         | 0.1282    | 0.1302    | 
99      | 0.0173         | 0.1281    | 0.13      | 
100     | 0.0372         | 0.1277    | 0.1297    | 
--------------------------------------------------
Finished sucessfully.
ERR@10 on training data: 0.1384
ERR@10 on validation data: 0.1445
---------------------------------
ERR@10 on test data: 0.1365
