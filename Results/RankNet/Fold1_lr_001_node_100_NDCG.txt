
Discard orig. features
Training data:	MSLR-WEB10K/Fold1/restructure_train.txt
Test data:	MSLR-WEB10K/Fold1/restructure_test.txt
Validation data:	MSLR-WEB10K/Fold1/restructure_vali.txt
Feature vector representation: Dense.
Ranking method:	RankNet
Feature description file:	Unspecified. All features will be used.
Train metric:	NDCG@10
Test metric:	NDCG@10
Feature normalization: No

[+] RankNet's Parameters:
No. of epochs: 100
No. of hidden layers: 1
No. of hidden nodes per layer: 100
Learning rate: 0.01

Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]... [Done.]            
(5946 ranked lists, 72342 entries read)
Reading feature file [MSLR-WEB10K/Fold1/restructure_vali.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_vali.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_vali.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_vali.txt]... [Done.]            
(1983 ranked lists, 23526 entries read)
Reading feature file [MSLR-WEB10K/Fold1/restructure_test.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_test.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_test.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_test.txt]... [Done.]            
(1980 ranked lists, 24153 entries read)
Initializing... [Done]
-----------------------------------------
Training starts...
--------------------------------------------------
#epoch  | % mis-ordered  | NDCG@10-T | NDCG@10-V | 
        |   pairs        |           |           | 
--------------------------------------------------
1       | 0.2267         | 0.5026    | 0.5017    | 
2       | 0.2            | 0.5074    | 0.5078    | 
3       | 0.2454         | 0.4854    | 0.4877    | 
4       | 0.2571         | 0.4881    | 0.4916    | 
5       | 0.2159         | 0.4992    | 0.4971    | 
6       | 0.2322         | 0.4872    | 0.4903    | 
7       | 0.2179         | 0.4907    | 0.4962    | 
8       | 0.2146         | 0.4928    | 0.4994    | 
9       | 0.239          | 0.4973    | 0.4991    | 
10      | 0.2225         | 0.4869    | 0.4905    | 
11      | 0.2145         | 0.4949    | 0.4967    | 
12      | 0.2234         | 0.4877    | 0.4942    | 
13      | 0.2094         | 0.49      | 0.4964    | 
14      | 0.2104         | 0.495     | 0.4956    | 
15      | 0.2123         | 0.5054    | 0.5027    | 
16      | 0.1802         | 0.4959    | 0.5025    | 
17      | 0.1724         | 0.4909    | 0.494     | 
18      | 0.1967         | 0.5051    | 0.51      | 
19      | 0.2382         | 0.4927    | 0.494     | 
20      | 0.1987         | 0.502     | 0.5058    | 
21      | 0.203          | 0.4914    | 0.4981    | 
22      | 0.22           | 0.4871    | 0.4934    | 
23      | 0.1985         | 0.4935    | 0.5       | 
24      | 0.1722         | 0.4928    | 0.5018    | 
25      | 0.1826         | 0.4918    | 0.4968    | 
26      | 0.2241         | 0.5036    | 0.509     | 
27      | 0.1962         | 0.5013    | 0.5017    | 
28      | 0.191          | 0.4904    | 0.4997    | 
29      | 0.1795         | 0.4932    | 0.493     | 
30      | 0.1764         | 0.4942    | 0.4883    | 
31      | 0.1987         | 0.4908    | 0.4931    | 
32      | 0.2235         | 0.5006    | 0.502     | 
33      | 0.2245         | 0.4945    | 0.4972    | 
34      | 0.1609         | 0.4916    | 0.4972    | 
35      | 0.2091         | 0.4979    | 0.4982    | 
36      | 0.1906         | 0.4929    | 0.497     | 
37      | 0.1795         | 0.4981    | 0.4962    | 
38      | 0.1906         | 0.4923    | 0.5005    | 
39      | 0.2092         | 0.4873    | 0.4923    | 
40      | 0.1724         | 0.5025    | 0.5066    | 
41      | 0.1741         | 0.4935    | 0.4958    | 
42      | 0.2003         | 0.4931    | 0.4998    | 
43      | 0.1069         | 0.4986    | 0.5025    | 
44      | 0.1323         | 0.4965    | 0.4943    | 
45      | 0.1893         | 0.4871    | 0.4923    | 
46      | 0.21           | 0.4977    | 0.4987    | 
47      | 0.2245         | 0.4937    | 0.4961    | 
48      | 0.1976         | 0.4939    | 0.4973    | 
49      | 0.1853         | 0.4937    | 0.4955    | 
50      | 0.1873         | 0.4895    | 0.4866    | 
51      | 0.2027         | 0.4926    | 0.4924    | 
52      | 0.2135         | 0.4962    | 0.4981    | 
53      | 0.1861         | 0.5005    | 0.5064    | 
54      | 0.1721         | 0.4849    | 0.4918    | 
55      | 0.1883         | 0.4901    | 0.4941    | 
56      | 0.2098         | 0.4994    | 0.5021    | 
57      | 0.1267         | 0.4977    | 0.4982    | 
58      | 0.0787         | 0.497     | 0.5008    | 
59      | 0.1739         | 0.4914    | 0.4876    | 
60      | 0.1949         | 0.4965    | 0.4978    | 
61      | 0.2205         | 0.4962    | 0.4967    | 
62      | 0.2094         | 0.4893    | 0.4969    | 
63      | 0.2265         | 0.4936    | 0.4972    | 
64      | 0.0946         | 0.4922    | 0.4951    | 
65      | 0.2055         | 0.4902    | 0.4925    | 
66      | 0.1597         | 0.4927    | 0.4966    | 
67      | 0.1238         | 0.4921    | 0.4951    | 
68      | 0.2007         | 0.4999    | 0.5033    | 
69      | 0.2078         | 0.4964    | 0.4988    | 
70      | 0.2088         | 0.4949    | 0.498     | 
71      | 0.2327         | 0.4924    | 0.4948    | 
72      | 0.1008         | 0.504     | 0.5068    | 
73      | 0.2117         | 0.4885    | 0.494     | 
74      | 0.1861         | 0.4919    | 0.4938    | 
75      | 0.1781         | 0.5001    | 0.4987    | 
76      | 0.1959         | 0.4967    | 0.4979    | 
77      | 0.1445         | 0.5003    | 0.5       | 
78      | 0.1532         | 0.4955    | 0.4944    | 
79      | 0.1214         | 0.4962    | 0.4922    | 
80      | 0.1849         | 0.4986    | 0.5       | 
81      | 0.2188         | 0.501     | 0.5041    | 
82      | 0.2034         | 0.4919    | 0.497     | 
83      | 0.2319         | 0.4948    | 0.4976    | 
84      | 0.202          | 0.5012    | 0.4984    | 
85      | 0.121          | 0.4915    | 0.4937    | 
86      | 0.1606         | 0.4979    | 0.4976    | 
87      | 0.1497         | 0.4985    | 0.4975    | 
88      | 0.1982         | 0.4925    | 0.4979    | 
89      | 0.1979         | 0.4859    | 0.4892    | 
90      | 0.1866         | 0.4893    | 0.4943    | 
91      | 0.1336         | 0.4948    | 0.5005    | 
92      | 0.2263         | 0.5046    | 0.501     | 
93      | 0.2199         | 0.4999    | 0.5021    | 
94      | 0.1408         | 0.4946    | 0.4996    | 
95      | 0.2169         | 0.5057    | 0.5055    | 
96      | 0.2148         | 0.4994    | 0.4972    | 
97      | 0.196          | 0.4929    | 0.4908    | 
98      | 0.1836         | 0.5009    | 0.4995    | 
99      | 0.2052         | 0.4896    | 0.4938    | 
100     | 0.2102         | 0.4933    | 0.4933    | 
--------------------------------------------------
Finished sucessfully.
NDCG@10 on training data: 0.5051
NDCG@10 on validation data: 0.51
---------------------------------
NDCG@10 on test data: 0.504
