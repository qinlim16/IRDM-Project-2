
Discard orig. features
Training data:	Fold1/restructure_train.txt
Test data:	Fold1/restructure_test.txt
Validation data:	Fold1/restructure_vali.txt
Feature vector representation: Dense.
Ranking method:	RankNet
Feature description file:	Unspecified. All features will be used.
Train metric:	NDCG@10
Test metric:	NDCG@10
Feature normalization: No

[+] RankNet's Parameters:
No. of epochs: 100
No. of hidden layers: 1
No. of hidden nodes per layer: 10
Learning rate: 0.03


Discard orig. features
Training data:	Fold1/restructure_train.txt
Test data:	Fold1/restructure_test.txt
Validation data:	Fold1/restructure_vali.txt
Feature vector representation: Dense.
Ranking method:	RankNet
Feature description file:	Unspecified. All features will be used.
Train metric:	NDCG@10
Test metric:	NDCG@10
Feature normalization: No

[+] RankNet's Parameters:
No. of epochs: 100
No. of hidden layers: 1
No. of hidden nodes per layer: 10
Learning rate: 0.03


Discard orig. features
Training data:	MSLR-WEB10K/Fold1/restructure_train.txt
Test data:	MSLR-WEB10K/Fold1/restructure_test.txt
Validation data:	MSLR-WEB10K/Fold1/restructure_vali.txt
Feature vector representation: Dense.
Ranking method:	RankNet
Feature description file:	Unspecified. All features will be used.
Train metric:	NDCG@10
Test metric:	NDCG@10
Feature normalization: No

[+] RankNet's Parameters:
No. of epochs: 100
No. of hidden layers: 1
No. of hidden nodes per layer: 10
Learning rate: 0.03

Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]... [Done.]            
(5946 ranked lists, 72342 entries read)
Reading feature file [MSLR-WEB10K/Fold1/restructure_vali.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_vali.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_vali.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_vali.txt]... [Done.]            
(1983 ranked lists, 23526 entries read)
Reading feature file [MSLR-WEB10K/Fold1/restructure_test.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_test.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_test.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_test.txt]... [Done.]            
(1980 ranked lists, 24153 entries read)
Initializing... [Done]
-----------------------------------------
Training starts...
--------------------------------------------------
#epoch  | % mis-ordered  | NDCG@10-T | NDCG@10-V | 
        |   pairs        |           |           | 
--------------------------------------------------
1       | 0.0902         | 0.4984    | 0.5026    | 
2       | 0.132          | 0.5021    | 0.503     | 
3       | 0.1415         | 0.4899    | 0.4983    | 
4       | 0.0487         | 0.4978    | 0.5053    | 
5       | 0.0725         | 0.4965    | 0.5009    | 
6       | 0.1121         | 0.4929    | 0.4956    | 
7       | 0.1238         | 0.494     | 0.5021    | 
8       | 0.1413         | 0.4916    | 0.5007    | 
9       | 0.1595         | 0.4927    | 0.5015    | 
10      | 0.0071         | 0.4976    | 0.4993    | 
11      | 0.0846         | 0.4937    | 0.4983    | 
12      | 0.0721         | 0.5023    | 0.5082    | 
13      | 0.0867         | 0.4942    | 0.4994    | 
14      | 0.0607         | 0.4941    | 0.4965    | 
15      | 0.0806         | 0.4933    | 0.4991    | 
16      | 0.0173         | 0.4976    | 0.501     | 
17      | 0.1299         | 0.496     | 0.4983    | 
18      | 0.0781         | 0.4971    | 0.5007    | 
19      | 0.0658         | 0.4956    | 0.5002    | 
20      | 0.0178         | 0.495     | 0.5013    | 
21      | 0.0159         | 0.4983    | 0.5023    | 
22      | 0.0649         | 0.4977    | 0.5002    | 
23      | 0.0665         | 0.4976    | 0.5004    | 
24      | 0.047          | 0.4984    | 0.501     | 
25      | 0.1065         | 0.4961    | 0.5028    | 
26      | 0.0472         | 0.4952    | 0.4993    | 
27      | 0.0547         | 0.4951    | 0.5006    | 
28      | 0.1119         | 0.4911    | 0.4951    | 
29      | 0.1147         | 0.4981    | 0.5021    | 
30      | 0.0628         | 0.4975    | 0.4994    | 
31      | 0.0911         | 0.5043    | 0.5076    | 
32      | 0.0582         | 0.4973    | 0.5009    | 
33      | 0.1206         | 0.4938    | 0.4976    | 
34      | 0.1599         | 0.4952    | 0.4991    | 
35      | 0.0712         | 0.4954    | 0.4999    | 
36      | 0.0918         | 0.4962    | 0.4991    | 
37      | 0.0645         | 0.4971    | 0.5035    | 
38      | 0.1424         | 0.4953    | 0.4967    | 
39      | 0.1483         | 0.4924    | 0.4992    | 
40      | 0.0497         | 0.497     | 0.503     | 
41      | 0.0718         | 0.4959    | 0.5003    | 
42      | 0.0236         | 0.4971    | 0.5029    | 
43      | 0.1119         | 0.5022    | 0.5016    | 
44      | 0.1            | 0.4953    | 0.4987    | 
45      | 0.0535         | 0.4956    | 0.5021    | 
46      | 0.0251         | 0.5001    | 0.5003    | 
47      | 0.0694         | 0.4965    | 0.4985    | 
48      | 0.0662         | 0.4952    | 0.5009    | 
49      | 0.1012         | 0.4971    | 0.5035    | 
50      | 0.0972         | 0.4959    | 0.4985    | 
51      | 0.0408         | 0.4956    | 0.5001    | 
52      | 0.0358         | 0.4983    | 0.5024    | 
53      | 0.12           | 0.504     | 0.5029    | 
54      | 0.1111         | 0.4983    | 0.4974    | 
55      | 0.1522         | 0.4917    | 0.4983    | 
56      | 0.0892         | 0.4988    | 0.5001    | 
57      | 0.0993         | 0.4961    | 0.5002    | 
58      | 0.0328         | 0.4949    | 0.5041    | 
59      | 0.0665         | 0.4968    | 0.498     | 
60      | 0.0544         | 0.496     | 0.502     | 
61      | 0.0272         | 0.498     | 0.5014    | 
62      | 0.1233         | 0.4973    | 0.4968    | 
63      | 0.0809         | 0.4956    | 0.5048    | 
64      | 0.0354         | 0.4956    | 0.5015    | 
65      | 0.0298         | 0.4983    | 0.5033    | 
66      | 0.1151         | 0.498     | 0.4982    | 
67      | 0.0645         | 0.4936    | 0.4984    | 
68      | 0.0773         | 0.4961    | 0.5013    | 
69      | 0.0376         | 0.4987    | 0.5022    | 
70      | 0.122          | 0.4974    | 0.5015    | 
71      | 0.0443         | 0.494     | 0.503     | 
72      | 0.0927         | 0.495     | 0.4986    | 
73      | 0.0554         | 0.4964    | 0.5031    | 
74      | 0.0392         | 0.4994    | 0.5009    | 
75      | 0.0406         | 0.4996    | 0.5013    | 
76      | 0.1558         | 0.4972    | 0.498     | 
77      | 0.0431         | 0.4959    | 0.5007    | 
78      | 0.064          | 0.4932    | 0.4996    | 
79      | 0.0395         | 0.4974    | 0.5025    | 
80      | 0.0715         | 0.4962    | 0.4978    | 
81      | 0.0486         | 0.4951    | 0.5       | 
82      | 0.0521         | 0.4977    | 0.4981    | 
83      | 0.0543         | 0.4992    | 0.5023    | 
84      | 0.0566         | 0.4986    | 0.5051    | 
85      | 0.1031         | 0.4961    | 0.4996    | 
86      | 0.0454         | 0.4943    | 0.5049    | 
87      | 0.0536         | 0.4959    | 0.5002    | 
88      | 0.047          | 0.4976    | 0.4994    | 
89      | 0.0458         | 0.4999    | 0.5009    | 
90      | 0.0581         | 0.4985    | 0.5033    | 
91      | 0.0842         | 0.4972    | 0.4986    | 
92      | 0.0405         | 0.4953    | 0.4997    | 
93      | 0.0443         | 0.4968    | 0.5001    | 
94      | 0.0485         | 0.4999    | 0.5024    | 
95      | 0.0613         | 0.5007    | 0.5048    | 
96      | 0.1497         | 0.4903    | 0.4989    | 
97      | 0.0392         | 0.4948    | 0.5025    | 
98      | 0.062          | 0.4948    | 0.5006    | 
99      | 0.0627         | 0.4957    | 0.5011    | 
100     | 0.0396         | 0.4947    | 0.5019    | 
--------------------------------------------------
Finished sucessfully.
NDCG@10 on training data: 0.5023
NDCG@10 on validation data: 0.5082
---------------------------------
NDCG@10 on test data: 0.4918

Discard orig. features
Training data:	MSLR-WEB10K/Fold1/restructure_train.txt
Test data:	MSLR-WEB10K/Fold1/restructure_test.txt
Validation data:	MSLR-WEB10K/Fold1/restructure_vali.txt
Feature vector representation: Dense.
Ranking method:	RankNet
Feature description file:	Unspecified. All features will be used.
Train metric:	NDCG@10
Test metric:	NDCG@10
Feature normalization: No

[+] RankNet's Parameters:
No. of epochs: 100
No. of hidden layers: 1
No. of hidden nodes per layer: 10
Learning rate: 0.05

Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]... [Done.]            
(5946 ranked lists, 72342 entries read)
Reading feature file [MSLR-WEB10K/Fold1/restructure_vali.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_vali.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_vali.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_vali.txt]... [Done.]            
(1983 ranked lists, 23526 entries read)
Reading feature file [MSLR-WEB10K/Fold1/restructure_test.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_test.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_test.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_test.txt]... [Done.]            
(1980 ranked lists, 24153 entries read)
Initializing... [Done]
-----------------------------------------
Training starts...
--------------------------------------------------
#epoch  | % mis-ordered  | NDCG@10-T | NDCG@10-V | 
        |   pairs        |           |           | 
--------------------------------------------------
1       | 0.1021         | 0.5058    | 0.5062    | 
2       | 0.1035         | 0.5073    | 0.5056    | 
3       | 0.1135         | 0.4891    | 0.4984    | 
4       | 0.1178         | 0.494     | 0.5031    | 
5       | 0.1394         | 0.492     | 0.4979    | 
6       | 0.2022         | 0.4936    | 0.4972    | 
7       | 0.039          | 0.4938    | 0.4998    | 
8       | 0.0712         | 0.4924    | 0.499     | 
9       | 0.1613         | 0.5036    | 0.5014    | 
10      | 0.0694         | 0.4955    | 0.4998    | 
11      | 0.0098         | 0.4953    | 0.5015    | 
12      | 0.1144         | 0.4892    | 0.4962    | 
13      | 0.0135         | 0.4974    | 0.5025    | 
14      | 0.1129         | 0.4987    | 0.5024    | 
15      | 0.0426         | 0.4933    | 0.4934    | 
16      | 0.0117         | 0.4959    | 0.5025    | 
17      | 0.0069         | 0.498     | 0.5011    | 
18      | 0.0086         | 0.4967    | 0.5004    | 
19      | 0.0823         | 0.4983    | 0.503     | 
20      | 0.0785         | 0.5039    | 0.5063    | 
21      | 0.0093         | 0.4954    | 0.5006    | 
22      | 0.0072         | 0.4953    | 0.5015    | 
23      | 0.0062         | 0.4954    | 0.5014    | 
24      | 0.0058         | 0.4957    | 0.5015    | 
25      | 0.0055         | 0.4957    | 0.5015    | 
26      | 0.0054         | 0.4958    | 0.5013    | 
27      | 0.0053         | 0.4958    | 0.5013    | 
28      | 0.0052         | 0.4958    | 0.5012    | 
29      | 0.0052         | 0.4958    | 0.5012    | 
30      | 0.0052         | 0.4959    | 0.5012    | 
31      | 0.004          | 0.4971    | 0.5004    | 
32      | 0.0041         | 0.4971    | 0.5003    | 
33      | 0.0042         | 0.4971    | 0.5002    | 
34      | 0.0043         | 0.4971    | 0.4999    | 
35      | 0.0046         | 0.4969    | 0.4999    | 
36      | 0.0049         | 0.4975    | 0.4999    | 
37      | 0.0057         | 0.4973    | 0.5001    | 
38      | 0.0072         | 0.4977    | 0.5003    | 
39      | 0.0472         | 0.498     | 0.4993    | 
40      | 0.0208         | 0.4951    | 0.5015    | 
41      | 0.1238         | 0.4953    | 0.4994    | 
42      | 0.0101         | 0.4956    | 0.5013    | 
43      | 0.0087         | 0.4972    | 0.502     | 
44      | 0.0118         | 0.4974    | 0.5028    | 
45      | 0.1277         | 0.4968    | 0.5001    | 
46      | 0.0956         | 0.4967    | 0.5031    | 
47      | 0.0159         | 0.4982    | 0.5027    | 
48      | 0.0896         | 0.4977    | 0.4991    | 
49      | 0.0204         | 0.4949    | 0.5011    | 
50      | 0.0237         | 0.4976    | 0.5028    | 
51      | 0.1058         | 0.4984    | 0.5026    | 
52      | 0.0381         | 0.4931    | 0.4923    | 
53      | 0.0108         | 0.4956    | 0.5016    | 
54      | 0.0736         | 0.4921    | 0.4977    | 
55      | 0.0321         | 0.4939    | 0.5001    | 
56      | 0.0191         | 0.4946    | 0.5007    | 
57      | 0.006          | 0.4975    | 0.5004    | 
58      | 0.0073         | 0.498     | 0.499     | 
59      | 0.04           | 0.4959    | 0.4986    | 
60      | 0.1214         | 0.4956    | 0.4968    | 
61      | 0.0111         | 0.497     | 0.5025    | 
62      | 0.1302         | 0.4974    | 0.4983    | 
63      | 0.0165         | 0.4952    | 0.5005    | 
64      | 0.0111         | 0.4953    | 0.5012    | 
65      | 0.0079         | 0.4978    | 0.5007    | 
66      | 0.0074         | 0.4974    | 0.5017    | 
67      | 0.1269         | 0.498     | 0.4986    | 
68      | 0.0102         | 0.496     | 0.5018    | 
69      | 0.01           | 0.4965    | 0.5019    | 
70      | 0.0124         | 0.4973    | 0.5024    | 
71      | 0.1113         | 0.4967    | 0.4996    | 
72      | 0.0232         | 0.4948    | 0.5001    | 
73      | 0.0175         | 0.4951    | 0.5005    | 
74      | 0.0169         | 0.4985    | 0.5026    | 
75      | 0.0589         | 0.4965    | 0.4999    | 
76      | 0.0367         | 0.4951    | 0.4988    | 
77      | 0.0391         | 0.4978    | 0.5036    | 
78      | 0.0638         | 0.4959    | 0.4986    | 
79      | 0.0231         | 0.4948    | 0.4998    | 
80      | 0.0198         | 0.4989    | 0.5031    | 
81      | 0.0558         | 0.4974    | 0.5       | 
82      | 0.0434         | 0.4951    | 0.498     | 
83      | 0.0276         | 0.4984    | 0.5045    | 
84      | 0.0989         | 0.4972    | 0.4995    | 
85      | 0.0253         | 0.4945    | 0.5004    | 
86      | 0.0229         | 0.4988    | 0.5035    | 
87      | 0.1098         | 0.4975    | 0.5002    | 
88      | 0.0266         | 0.4946    | 0.5002    | 
89      | 0.0199         | 0.4989    | 0.503     | 
90      | 0.0268         | 0.4987    | 0.5032    | 
91      | 0.1084         | 0.5012    | 0.5062    | 
92      | 0.02           | 0.4951    | 0.501     | 
93      | 0.0147         | 0.4953    | 0.5006    | 
94      | 0.0132         | 0.4952    | 0.5011    | 
95      | 0.0127         | 0.495     | 0.5014    | 
96      | 0.0108         | 0.4968    | 0.5011    | 
97      | 0.0115         | 0.4969    | 0.501     | 
98      | 0.0138         | 0.4977    | 0.5022    | 
99      | 0.0223         | 0.4984    | 0.5019    | 
100     | 0.1036         | 0.5041    | 0.5092    | 
--------------------------------------------------
Finished sucessfully.
NDCG@10 on training data: 0.5041
NDCG@10 on validation data: 0.5092
---------------------------------
NDCG@10 on test data: 0.493

Discard orig. features
Training data:	MSLR-WEB10K/Fold1/restructure_train.txt
Test data:	MSLR-WEB10K/Fold1/restructure_test.txt
Validation data:	MSLR-WEB10K/Fold1/restructure_vali.txt
Feature vector representation: Dense.
Ranking method:	RankNet
Feature description file:	Unspecified. All features will be used.
Train metric:	NDCG@10
Test metric:	NDCG@10
Feature normalization: No

[+] RankNet's Parameters:
No. of epochs: 100
No. of hidden layers: 1
No. of hidden nodes per layer: 10
Learning rate: 0.03

Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_train.txt]... [Done.]            
(5946 ranked lists, 72342 entries read)
Reading feature file [MSLR-WEB10K/Fold1/restructure_vali.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_vali.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_vali.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_vali.txt]... [Done.]            
(1983 ranked lists, 23526 entries read)
Reading feature file [MSLR-WEB10K/Fold1/restructure_test.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_test.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_test.txt]: 0... Reading feature file [MSLR-WEB10K/Fold1/restructure_test.txt]... [Done.]            
(1980 ranked lists, 24153 entries read)
Initializing... [Done]
-----------------------------------------
Training starts...
--------------------------------------------------
#epoch  | % mis-ordered  | NDCG@10-T | NDCG@10-V | 
        |   pairs        |           |           | 
--------------------------------------------------
1       | 0.137          | 0.4906    | 0.4993    | 
2       | 0.1341         | 0.5078    | 0.514     | 
3       | 0.0749         | 0.5046    | 0.5038    | 
4       | 0.1001         | 0.4926    | 0.4985    | 
5       | 0.1641         | 0.4977    | 0.4987    | 
6       | 0.16           | 0.4905    | 0.4971    | 
7       | 0.1136         | 0.4924    | 0.4966    | 
8       | 0.0979         | 0.4915    | 0.4985    | 
9       | 0.1806         | 0.5026    | 0.5019    | 
10      | 0.158          | 0.499     | 0.4973    | 
11      | 0.1543         | 0.4962    | 0.4995    | 
12      | 0.113          | 0.4976    | 0.5012    | 
13      | 0.0433         | 0.4965    | 0.5035    | 
14      | 0.0714         | 0.4989    | 0.4967    | 
15      | 0.1694         | 0.4927    | 0.5006    | 
16      | 0.0626         | 0.5003    | 0.5067    | 
17      | 0.0957         | 0.4959    | 0.501     | 
18      | 0.1123         | 0.5031    | 0.5099    | 
19      | 0.0629         | 0.4954    | 0.4975    | 
20      | 0.0357         | 0.4981    | 0.5024    | 
21      | 0.1096         | 0.5007    | 0.5057    | 
22      | 0.0674         | 0.4964    | 0.4966    | 
23      | 0.0341         | 0.4979    | 0.5011    | 
24      | 0.1658         | 0.4951    | 0.4987    | 
25      | 0.0772         | 0.4969    | 0.5012    | 
26      | 0.0422         | 0.4954    | 0.5007    | 
27      | 0.0412         | 0.4959    | 0.5026    | 
28      | 0.107          | 0.4982    | 0.5022    | 
29      | 0.0528         | 0.4968    | 0.5016    | 
30      | 0.0449         | 0.4963    | 0.5026    | 
31      | 0.0206         | 0.4965    | 0.5014    | 
32      | 0.0736         | 0.4978    | 0.4956    | 
33      | 0.0738         | 0.4979    | 0.5023    | 
34      | 0.0724         | 0.4967    | 0.4989    | 
35      | 0.0449         | 0.4956    | 0.5003    | 
36      | 0.0918         | 0.4973    | 0.5011    | 
37      | 0.0651         | 0.4973    | 0.5016    | 
38      | 0.0585         | 0.4956    | 0.5004    | 
39      | 0.0751         | 0.4966    | 0.5013    | 
40      | 0.1046         | 0.4975    | 0.4971    | 
41      | 0.087          | 0.4955    | 0.4991    | 
42      | 0.081          | 0.4982    | 0.5047    | 
43      | 0.162          | 0.4907    | 0.4984    | 
44      | 0.0843         | 0.4963    | 0.5008    | 
45      | 0.0491         | 0.4971    | 0.4998    | 
46      | 0.0701         | 0.4957    | 0.5004    | 
47      | 0.0562         | 0.4966    | 0.5035    | 
48      | 0.0428         | 0.4977    | 0.4997    | 
49      | 0.0594         | 0.4973    | 0.5005    | 
50      | 0.0655         | 0.4978    | 0.5002    | 
51      | 0.1305         | 0.5024    | 0.5071    | 
52      | 0.1608         | 0.4987    | 0.5016    | 
53      | 0.0791         | 0.4949    | 0.5012    | 
54      | 0.0436         | 0.4957    | 0.5026    | 
55      | 0.0387         | 0.4976    | 0.5006    | 
56      | 0.0878         | 0.4972    | 0.4981    | 
57      | 0.1491         | 0.4889    | 0.4974    | 
58      | 0.0408         | 0.4974    | 0.5019    | 
59      | 0.089          | 0.4969    | 0.4978    | 
60      | 0.0512         | 0.4964    | 0.5031    | 
61      | 0.0456         | 0.4957    | 0.4986    | 
62      | 0.0827         | 0.4986    | 0.4993    | 
63      | 0.1284         | 0.498     | 0.4977    | 
64      | 0.1423         | 0.4945    | 0.4991    | 
65      | 0.109          | 0.4979    | 0.4983    | 
66      | 0.07           | 0.4973    | 0.5025    | 
67      | 0.1221         | 0.4956    | 0.5011    | 
68      | 0.0628         | 0.4981    | 0.5017    | 
69      | 0.084          | 0.4983    | 0.4974    | 
70      | 0.1283         | 0.4969    | 0.5025    | 
71      | 0.0325         | 0.4953    | 0.5019    | 
72      | 0.1235         | 0.4968    | 0.4994    | 
73      | 0.1147         | 0.4968    | 0.4979    | 
74      | 0.045          | 0.4938    | 0.5038    | 
75      | 0.0401         | 0.4994    | 0.5025    | 
76      | 0.1215         | 0.5035    | 0.5072    | 
77      | 0.0417         | 0.4968    | 0.5013    | 
78      | 0.0674         | 0.4974    | 0.4976    | 
79      | 0.1349         | 0.5028    | 0.5084    | 
80      | 0.1305         | 0.5053    | 0.5114    | 
81      | 0.0669         | 0.4982    | 0.4994    | 
82      | 0.0628         | 0.4953    | 0.5011    | 
83      | 0.0355         | 0.4955    | 0.5008    | 
84      | 0.0431         | 0.498     | 0.5032    | 
85      | 0.0712         | 0.4982    | 0.5001    | 
86      | 0.0475         | 0.4978    | 0.499     | 
87      | 0.0519         | 0.4977    | 0.5045    | 
88      | 0.0495         | 0.4989    | 0.5028    | 
89      | 0.1313         | 0.5015    | 0.5061    | 
90      | 0.0501         | 0.4959    | 0.5016    | 
91      | 0.0582         | 0.499     | 0.5032    | 
92      | 0.0577         | 0.4954    | 0.4968    | 
93      | 0.0635         | 0.4981    | 0.5066    | 
94      | 0.0631         | 0.4961    | 0.502     | 
95      | 0.0575         | 0.4956    | 0.4999    | 
96      | 0.0475         | 0.4954    | 0.5011    | 
97      | 0.0431         | 0.498     | 0.5038    | 
98      | 0.0461         | 0.4983    | 0.4997    | 
99      | 0.043          | 0.4968    | 0.4986    | 
100     | 0.0426         | 0.4982    | 0.5018    | 
--------------------------------------------------
Finished sucessfully.
NDCG@10 on training data: 0.5078
NDCG@10 on validation data: 0.514
---------------------------------
NDCG@10 on test data: 0.4992
